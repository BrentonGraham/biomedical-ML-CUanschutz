{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca722dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22805422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set wkdir\n",
    "WORK_DIR = os.getcwd()\n",
    "\n",
    "# Import training, validation and test sets\n",
    "trainingDataDF = pd.read_excel(f'{WORK_DIR}/Pilot_GeneExpressionData.xlsx')\n",
    "testDataDF = pd.read_excel(f'{WORK_DIR}/Pilot_GeneExpressionData.xlsx')\n",
    "testDataDF = pd.read_excel(f'{WORK_DIR}/Pilot_GeneExpressionData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8935d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nFeatures):\n",
    "        '''\n",
    "        Constructer\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.nFeatures = nFeatures\n",
    "        self.batchSize = 500\n",
    "        self.learningRate = 0.001\n",
    "        self.nEpochs = 250\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.nFeatures, 20),\n",
    "            torch.nn.Sigmoid()       # Activation function after every layer\n",
    "            torch.nn.Linear(20, 1)   # In the last layer we are estimating a probability, so need output of 1\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, features):\n",
    "        '''\n",
    "        Do forward operation\n",
    "        '''\n",
    "        return self.fc(features)\n",
    "        \n",
    "        \n",
    "    def trainModel(self, trainingFeatures, trainingLabels):\n",
    "        '''\n",
    "        Do training\n",
    "        '''\n",
    "        nTrainingSamples = trainingFeatures.shape[0]\n",
    "        nTrainingBatches = nTrainingSamples // self.batchSize\n",
    "        if nTrainingBatches * self.batchSize < nTrainingSamples:\n",
    "            nTrainingBatches += 1\n",
    "            \n",
    "        # Moving to GPU\n",
    "        device = torch.device('cpu')\n",
    "        model = self\n",
    "        model.to(device=device)\n",
    "        \n",
    "        # Optimization\n",
    "        loss = torch.nn.BCELoss() # Loss function\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=self.learningRate, momentum) # Optimization approach\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(self.nEpochs):\n",
    "            # -> training mode\n",
    "            model.train()\n",
    "            \n",
    "            epochLoss = 0\n",
    "            epochAccuracy = 0\n",
    "            for batch in range(nTrainingBatches):\n",
    "                \n",
    "                # Zeroing gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Numpy -> tensor data conversion\n",
    "                x = torch.tensor(\n",
    "                    trainingFeatures[batch*self.batchSize:(batch+1)*self.batchSize, :], \n",
    "                    device=device, \n",
    "                    dtype=torch.float32)\n",
    "                \n",
    "                y = torch.tensor(\n",
    "                    trainingLabels[batch*self.batchSize:(batch+1)*self.batchSize, :], \n",
    "                    device=device, \n",
    "                    dtype=torch.float32)\n",
    "                \n",
    "                # Forward\n",
    "                y_pred = model(x)\n",
    "                batchLoss = loss(y_pred, y) # Loss computation\n",
    "                batchLoss.backward()        # Backpropagate\n",
    "                optimizer.step()            # Update parameters\n",
    "                epochLoss += batchLoss.data * x.shape[0] / nTrainingSamples\n",
    "                \n",
    "                labels_pred = torch.round(y_pred)\n",
    "                correct = (y == labels_pred).float()\n",
    "                accuracy = correct.sum() / correct.numel()\n",
    "                \n",
    "                epochAccuracy += accuracy * 100 * x.shape[0] / nTrainingSamples\n",
    "                \n",
    "                print('Print accuracy and loss')\n",
    "            \n",
    "            # Validation\n",
    "            model.train(False)\n",
    "            # Repeat forward operation on validation dataset\n",
    "            \n",
    "    def save():\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
